// gui_blog_scraper/main.js
const { app, BrowserWindow, ipcMain, dialog, shell, Menu } = require('electron');
const path = require('path');
const fs = require('fs');
const puppeteer = require('puppeteer');

// Define debug log path
const debugLogPath = path.join(app.getPath('userData'), 'debug.log');
const debugLogStream = fs.createWriteStream(debugLogPath, { flags: 'a' });
function log(msg) {
  const timestamp = new Date().toISOString();
  debugLogStream.write(`[${timestamp}] ${msg}\n`);
}

// Write out debug path reference file
try {
  fs.writeFileSync(path.join(__dirname, 'debug_log_path.txt'), debugLogPath);
} catch (e) {
  log(`Failed to write debug_log_path.txt: ${e.message}`);
}

let mainWindow;
let lastScrapeDir = null; // Track the last written scrape folder
const selectorStorePath = path.join(app.getPath('userData'), 'selectors.json');

function createWindow() {
  try {
    log('Creating browser window...');
    mainWindow = new BrowserWindow({
      width: 650,
      height: 700,
      webPreferences: {
        nodeIntegration: true,
        contextIsolation: false
      },
      icon: path.join(__dirname, 'scraper.ico')
    });

    log('Loading index.html...');
    mainWindow.loadFile(path.resolve(__dirname, 'index.html'))
      .catch(err => {
        console.error("Failed to load index.html:", err);
        fs.writeFileSync('load_error.log', err.stack);
      });
    log('Window created and file loaded.');
  } catch (err) {
    log(`ERROR during window creation: ${err.message}`);
  }
}

app.whenReady().then(() => {
  const template = [
    {
      label: "File",
      submenu: [
        {
          label: "Exit",
          accelerator: "CmdOrCtrl+Q",
          click: () => app.quit()
        }
      ]
    },
    {
      label: "Options",
      submenu: [
        {
          label: "Debug Logs",
          click: () => shell.openPath(debugLogPath)
        },
        {
          label: "Clear History",
          click: () => {
            if (fs.existsSync(selectorStorePath)) {
              fs.unlinkSync(selectorStorePath);
              log(`Cleared selector history at ${selectorStorePath}`);
              dialog.showMessageBox({
                type: 'info',
                message: 'Scrape history has been cleared.'
              });
            } else {
              dialog.showMessageBox({
                type: 'info',
                message: 'No scrape history to clear.'
              });
            }
          }
        }
      ]
    },
    {
      label: "Help",
      submenu: [
        {
          label: "README",
          click: async () => shell.openExternal("http://github.garrettspear.info/ScrapeWeb/")
        },
        {
          label: "Wiki",
          click: async () => shell.openExternal("https://github.com/garrettds11/ScrapeWeb/wiki")
        },
        {
          label: "About",
          click: () => {
            dialog.showMessageBox({
              type: "info",
              title: "About ScrapeWeb",
              message: `ScrapeWeb v${app.getVersion()}`,
              detail: "A GUI-based blog scraper built with Electron and Puppeteer.\nÂ© 2025 Garrett Spear\n\nhttps://github.garrettspear.info/ScrapeWeb/",
              buttons: ["Close"]
            });
          }
        },
        {
          label: "Donate",
          click: async () => shell.openExternal("https://paypal.me/spear2018/")
        }
      ]
    }
  ];

  const menu = Menu.buildFromTemplate(template);
  Menu.setApplicationMenu(menu);

  log('App is ready.');
  createWindow();
});

ipcMain.handle('select-folder', async () => {
  const result = await dialog.showOpenDialog({ properties: ['openDirectory'] });
  return result.canceled ? null : result.filePaths[0];
});

ipcMain.handle('open-scrapes-folder', async () => {
  const target = lastScrapeDir;
  if (target && fs.existsSync(target)) {
    shell.openPath(target);
    log(`Opened folder: ${target}`);
  } else {
    log(`Tried to open missing folder: ${target}`);
  }
});

ipcMain.handle('get-selector-history', async () => {
  try {
    if (fs.existsSync(selectorStorePath)) {
      const data = fs.readFileSync(selectorStorePath, 'utf-8');
      return JSON.parse(data);
    }
  } catch (e) {
    log(`Error reading selector history: ${e.message}`);
  }
  return {};
});

ipcMain.handle('scrape', async (event, { url, titleSelector, linkSelector, outputFormat, outputDir }) => {
  const timestamp = new Date().toISOString().replace(/[:]/g, '-').split('.')[0];
  const scrapeDir = path.join(outputDir || app.getPath('documents'), 'BlogScraper', 'scrapes', timestamp);
  fs.mkdirSync(scrapeDir, { recursive: true });
  lastScrapeDir = scrapeDir;
  log(`lastScrapeDir set to: ${lastScrapeDir}`);

  log(`\n--- New Scrape Started ---`);
  log(`Target URL: ${url}`);
  log(`Title Selector: ${titleSelector}`);
  log(`Link Selector: ${linkSelector}`);

  let browser;
  try {
    browser = await puppeteer.launch({ headless: true });
    const page = await browser.newPage();
    await page.goto(url, { waitUntil: 'networkidle2' });
    await page.waitForSelector(titleSelector, { timeout: 10000 });

    const metadata = await page.evaluate(() => {
      return {
        title: document.title || '',
        author: document.querySelector('meta[name="author"]')?.content || '',
        description: document.querySelector('meta[name="description"]')?.content || '',
        updated: document.querySelector('meta[property="og:updated_time"]')?.content || ''
      };
    });

    const postHandles = await page.$$(titleSelector);
    log(`Found ${postHandles.length} elements with the title selector.`);

    const posts = [];
    let current = 0;

    for (const el of postHandles) {
      const result = await page.evaluate((element, linkSel) => {
        const anchorHref = element.href ||
                           element.querySelector(linkSel)?.href ||
                           element.closest('a')?.href || '';
        return {
          title: element.innerText.trim(),
          url: anchorHref,
          content: element.innerText.trim()
        };
      }, el, linkSelector);

      posts.push(result);
      current++;
      if (mainWindow && mainWindow.setProgressBar) {
        mainWindow.setProgressBar(current / postHandles.length);
      }
    }

    if (outputFormat === 'json' || outputFormat === 'both') {
      const jsonOut = path.join(scrapeDir, `scrape_${timestamp}.json`);
      const jsonFull = { url, ...metadata, posts };
      fs.writeFileSync(jsonOut, JSON.stringify(jsonFull, null, 2));
      log(`JSON file written: ${jsonOut}`);
    }

    if (outputFormat === 'markdown' || outputFormat === 'both') {
      const mdOut = path.join(scrapeDir, `scrape_${timestamp}.md`);
      const lines = [
        `# ${metadata.title}`,
        `**URL:** ${url}`,
        `**Author:** ${metadata.author}`,
        `**Last Updated:** ${metadata.updated}`,
        `**Description:** ${metadata.description}`,
        `\n## Posts\n`
      ];
      posts.forEach((p, i) => {
        lines.push(`${i + 1}. [${p.title}](${p.url})`);
      });
      fs.writeFileSync(mdOut, lines.join('\n'));
      log(`Markdown file written: ${mdOut}`);
    }

    // Save selectors to history
    let allHistory = {};
    try {
      if (fs.existsSync(selectorStorePath)) {
        const existing = fs.readFileSync(selectorStorePath, 'utf-8');
        allHistory = JSON.parse(existing);
      }
    } catch (e) {
      log(`Failed to load existing selector history: ${e.message}`);
    }
    allHistory[url] = { titleSelector, linkSelector };
    try {
      fs.writeFileSync(selectorStorePath, JSON.stringify(allHistory, null, 2));
      log(`Saved selectors to history for ${url}`);
    } catch (e) {
      log(`Failed to save selector history: ${e.message}`);
    }
  
    await browser.close();
    if (mainWindow && mainWindow.setProgressBar) {
      mainWindow.setProgressBar(-1);
    }

    log(`Scrape finished successfully.`);
    return scrapeDir;
  } catch (error) {
    if (browser) await browser.close();
    log(`Scraping failed: ${error.message}`);
    if (mainWindow && mainWindow.setProgressBar) {
      mainWindow.setProgressBar(-1);
    }
    throw new Error(`Scraping failed: ${error.message}`);
  }
});
